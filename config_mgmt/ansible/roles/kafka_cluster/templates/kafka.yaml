apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: {{ kafka_cluster }}
spec:
  kafka:
    version: {{ kafka_version }}
    replicas: {{ kafka_replicas }}
    listeners:
      - name: plain
        port: {{ kafka_bootstrap_port }}
        type: internal
        tls: false
      - name: tls
        port: 9093
        type: internal
        tls: true

      # https://access.redhat.com/documentation/en-us/red_hat_amq/2021.q3/html/using_amq_streams_on_openshift/assembly-configuring-external-listeners-str#proc-accessing-kafka-using-routes-str
      - name: external
        port: 9094
        type: route
        tls: true

    resources:
      requests:
        cpu: '{{ kafka_requests_cpu }}'
        memory: '{{ kafka_requests_memory }}'
      limits:
        cpu: '{{ kafka_limits_cpu }}'
        memory: '{{ kafka_limits_memory }}'
    livenessProbe:
      initialDelaySeconds: {{ kafka_liveness_probe_initial_delay_seconds }}
      timeoutSeconds: {{ kafka_liveness_probe_timeout_seconds }}
    readinessProbe:
      initialDelaySeconds: {{ kafka_readiness_probe_initial_delay_seconds }}
      timeoutSeconds: {{ kafka_readiness_probe_timeout_seconds }}
    jvmOptions:
      gcLoggingEnabled: false
{% if enable_metrics|bool == true %}
    metrics:
      # Inspired by config from Kafka 2.0.0 example rules:
      # https://github.com/prometheus/jmx_exporter/blob/master/example_configs/kafka-2_0_0.yml
      lowercaseOutputName: true
      rules:
      # Special cases and very specific rules
      - pattern: kafka.server<type=(.+), name=(.+), clientId=(.+), topic=(.+), partition=(.*)><>Value
        name: kafka_server_$1_$2
        type: GAUGE
        labels:
          clientId: "$3"
          topic: "$4"
          partition: "$5"
      - pattern: kafka.server<type=(.+), name=(.+), clientId=(.+), brokerHost=(.+), brokerPort=(.+)><>Value
        name: kafka_server_$1_$2
        type: GAUGE
        labels:
          clientId: "$3"
          broker: "$4:$5"
      - pattern: kafka.server<type=(.+), cipher=(.+), protocol=(.+), listener=(.+), networkProcessor=(.+)><>connections
        name: kafka_server_$1_connections_tls_info
        type: GAUGE
        labels:
          listener: "$2"
          networkProcessor: "$3"
          protocol: "$4"
          cipher: "$5"
      - pattern: kafka.server<type=(.+), clientSoftwareName=(.+), clientSoftwareVersion=(.+), listener=(.+), networkProcessor=(.+)><>connections
        name: kafka_server_$1_connections_software
        type: GAUGE
        labels:
          clientSoftwareName: "$2"
          clientSoftwareVersion: "$3"
          listener: "$4"
          networkProcessor: "$5"
      - pattern: "kafka.server<type=(.+), listener=(.+), networkProcessor=(.+)><>(.+):"
        name: kafka_server_$1_$4
        type: GAUGE
        labels:
          listener: "$2"
          networkProcessor: "$3"
      - pattern: kafka.server<type=(.+), listener=(.+), networkProcessor=(.+)><>(.+)
        name: kafka_server_$1_$4
        type: GAUGE
        labels:
          listener: "$2"
          networkProcessor: "$3"
      # Some percent metrics use MeanRate attribute
      # Ex) kafka.server<type=(KafkaRequestHandlerPool), name=(RequestHandlerAvgIdlePercent)><>MeanRate
      - pattern: kafka.(\w+)<type=(.+), name=(.+)Percent\w*><>MeanRate
        name: kafka_$1_$2_$3_percent
        type: GAUGE
      # Generic gauges for percents
      - pattern: kafka.(\w+)<type=(.+), name=(.+)Percent\w*><>Value
        name: kafka_$1_$2_$3_percent
        type: GAUGE
      - pattern: kafka.(\w+)<type=(.+), name=(.+)Percent\w*, (.+)=(.+)><>Value
        name: kafka_$1_$2_$3_percent
        type: GAUGE
        labels:
          "$4": "$5"
      # Generic per-second counters with 0-2 key/value pairs
      - pattern: kafka.(\w+)<type=(.+), name=(.+)PerSec\w*, (.+)=(.+), (.+)=(.+)><>Count
        name: kafka_$1_$2_$3_total
        type: COUNTER
        labels:
          "$4": "$5"
          "$6": "$7"
      - pattern: kafka.(\w+)<type=(.+), name=(.+)PerSec\w*, (.+)=(.+)><>Count
        name: kafka_$1_$2_$3_total
        type: COUNTER
        labels:
          "$4": "$5"
      - pattern: kafka.(\w+)<type=(.+), name=(.+)PerSec\w*><>Count
        name: kafka_$1_$2_$3_total
        type: COUNTER
      # Generic gauges with 0-2 key/value pairs
      - pattern: kafka.(\w+)<type=(.+), name=(.+), (.+)=(.+), (.+)=(.+)><>Value
        name: kafka_$1_$2_$3
        type: GAUGE
        labels:
          "$4": "$5"
          "$6": "$7"
      - pattern: kafka.(\w+)<type=(.+), name=(.+), (.+)=(.+)><>Value
        name: kafka_$1_$2_$3
        type: GAUGE
        labels:
          "$4": "$5"
      - pattern: kafka.(\w+)<type=(.+), name=(.+)><>Value
        name: kafka_$1_$2_$3
        type: GAUGE
      # Emulate Prometheus 'Summary' metrics for the exported 'Histogram's.
      # Note that these are missing the '_sum' metric!
      - pattern: kafka.(\w+)<type=(.+), name=(.+), (.+)=(.+), (.+)=(.+)><>Count
        name: kafka_$1_$2_$3_count
        type: COUNTER
        labels:
          "$4": "$5"
          "$6": "$7"
      - pattern: kafka.(\w+)<type=(.+), name=(.+), (.+)=(.*), (.+)=(.+)><>(\d+)thPercentile
        name: kafka_$1_$2_$3
        type: GAUGE
        labels:
          "$4": "$5"
          "$6": "$7"
          quantile: "0.$8"
      - pattern: kafka.(\w+)<type=(.+), name=(.+), (.+)=(.+)><>Count
        name: kafka_$1_$2_$3_count
        type: COUNTER
        labels:
          "$4": "$5"
      - pattern: kafka.(\w+)<type=(.+), name=(.+), (.+)=(.*)><>(\d+)thPercentile
        name: kafka_$1_$2_$3
        type: GAUGE
        labels:
          "$4": "$5"
          quantile: "0.$6"
      - pattern: kafka.(\w+)<type=(.+), name=(.+)><>Count
        name: kafka_$1_$2_$3_count
        type: COUNTER
      - pattern: kafka.(\w+)<type=(.+), name=(.+)><>(\d+)thPercentile
        name: kafka_$1_$2_$3
        type: GAUGE
        labels:
          quantile: "0.$4"
{% endif %}
    config:
      default.replication.factor: {{ kafka_default_replication_factor }}
      offsets.topic.replication.factor: {{ kafka_offsets_topic_replication_factor }}
      transaction.state.log.replication.factor: {{ kafka_transaction_state_log_replication_factor }}
      transaction.state.log.min.isr: {{ transaction_state_log_min_isr }}

      min.insync.replicas: 1

      inter.broker.protocol.version: {{ kafka_log_message_format_version }}
    storage:
{% if kafka_storage_type == "persistent" %}
      type: persistent-claim
      size: {{ kafka_volume_capacity }}
      deleteClaim: {{ kafka_delete_claim }}
{% endif %}
{% if kafka_storage_type == "ephemeral" %}
      type: ephemeral
{% endif %}
  zookeeper:
    replicas: {{ zookeeper_replicas }}
    resources:
      requests:
        cpu: '{{ zookeeper_requests_cpu }}'
        memory: '{{ zookeeper_requests_memory }}'
      limits:
        cpu: '{{ zookeeper_limits_cpu }}'
        memory: '{{ zookeeper_limits_memory }}'
    readinessProbe:
      initialDelaySeconds: {{ zookeeper_readiness_probe_initial_delay_seconds }}
      timeoutSeconds: {{ zookeeper_readiness_probe_timeout_seconds }}
    livenessProbe:
      initialDelaySeconds: {{ zookeeper_liveness_probe_initial_delay_seconds }}
      timeoutSeconds: {{ zookeeper_liveness_probe_timeout_seconds }}
{% if enable_metrics|bool == true %}
    metrics:
      # Inspired by Zookeeper rules
      # https://github.com/prometheus/jmx_exporter/blob/master/example_configs/zookeeper.yaml
      lowercaseOutputName: true
      rules:
      # replicated Zookeeper
      - pattern: "org.apache.ZooKeeperService<name0=ReplicatedServer_id(\\d+)><>(\\w+)"
        name: "zookeeper_$2"
        type: GAUGE
      - pattern: "org.apache.ZooKeeperService<name0=ReplicatedServer_id(\\d+), name1=replica.(\\d+)><>(\\w+)"
        name: "zookeeper_$3"
        type: GAUGE
        labels:
          replicaId: "$2"
      - pattern: "org.apache.ZooKeeperService<name0=ReplicatedServer_id(\\d+), name1=replica.(\\d+), name2=(\\w+)><>(Packets\\w+)"
        name: "zookeeper_$4"
        type: COUNTER
        labels:
          replicaId: "$2"
          memberType: "$3"
      - pattern: "org.apache.ZooKeeperService<name0=ReplicatedServer_id(\\d+), name1=replica.(\\d+), name2=(\\w+)><>(\\w+)"
        name: "zookeeper_$4"
        type: GAUGE
        labels:
          replicaId: "$2"
          memberType: "$3"
      - pattern: "org.apache.ZooKeeperService<name0=ReplicatedServer_id(\\d+), name1=replica.(\\d+), name2=(\\w+), name3=(\\w+)><>(\\w+)"
        name: "zookeeper_$4_$5"
        type: GAUGE
        labels:
          replicaId: "$2"
          memberType: "$3"
{% endif %}
    storage:
{% if zookeeper_storage_type == "persistent" %}
      type: persistent-claim
      size: {{ zookeeper_volume_capacity }}
      deleteClaim: {{ zookeeper_delete_claim }}
{% endif %}
{% if zookeeper_storage_type == "ephemeral" %}
      type: ephemeral
{% endif %}
  entityOperator:
    topicOperator:
      resources:
        requests:
          cpu: "{{ topic_operator_requests_cpu }}"
          memory: {{ topic_operator_requests_memory }}
        limits:
          cpu: "{{ topic_operator_limits_cpu }}"
          memory: {{ topic_operator_limits_memory }}
      readinessProbe:
        initialDelaySeconds: {{ topic_operator_readiness_probe_initial_delay_seconds }}
        timeoutSeconds: {{ topic_operator_readiness_probe_timeout_seconds }}
      livenessProbe:
        initialDelaySeconds: {{ topic_operator_liveness_probe_initial_delay_seconds }}
        timeoutSeconds: {{ topic_operator_liveness_probe_timeout_seconds }}
    userOperator: 
      resources:
        requests:
          cpu: "{{ user_operator_requests_cpu }}"
          memory: {{ user_operator_requests_memory }}
        limits:
          cpu: "{{ user_operator_limits_cpu }}"
          memory: {{ user_operator_limits_memory }}
      readinessProbe:
        initialDelaySeconds: {{ user_operator_readiness_probe_initial_delay_seconds }}
        timeoutSeconds: {{ user_operator_readiness_probe_timeout_seconds }}
      livenessProbe:
        initialDelaySeconds: {{ user_operator_liveness_probe_initial_delay_seconds }}
        timeoutSeconds: {{ user_operator_liveness_probe_timeout_seconds }}
  kafkaExporter:
    groupRegex: ".*"
    topicRegex: "^topic-.+"
    resources:
      requests:
        cpu: 200m
        memory: 64Mi
      limits:
        cpu: 500m
        memory: 128Mi
    logging: warn
    enableSaramaLogging: true
    readinessProbe: 
      initialDelaySeconds: 15
      timeoutSeconds: 5
    livenessProbe: 
      initialDelaySeconds: 15
      timeoutSeconds: 5
